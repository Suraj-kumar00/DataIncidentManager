id: incident_analyzer
namespace: incident_management
description: "AI Agent analyzes incidents and makes autonomous decisions"

inputs:
  - id: alert_data
    type: STRING
    description: "Enriched alert data from ingestion flow"
  
  - id: incident_id
    type: STRING
    description: "Unique incident identifier"

tasks:
  # Step 1: Gather context from Snowflake (simulated)
  - id: gather_snowflake_context
    type: io.kestra.plugin.scripts.python.Script
    docker:
      image: python:3.11-slim
    script: |
      import json
      from datetime import datetime
      
      alert = json.loads("""{{ inputs.alert_data }}""")
      
      # Simulate Snowflake API call
      # In production: would query actual Snowflake metadata API
      context = {
          "system": "snowflake",
          "tables_affected": ["customer_events", "customer_analytics"],
          "last_schema_change": datetime.now().isoformat(),
          "data_latency_minutes": 120,
          "rows_updated_today": 5400000,
          "is_critical_for_reporting": True,
          "query_performance": "degraded"
      }
      
      print(f"✓ Gathered Snowflake context")
      
      # Write output for AI Agent
      with open('snowflake_context.json', 'w') as f:
          json.dump(context, f)
    outputFiles:
      - snowflake_context.json

  # Step 2: Gather context from Airflow (simulated)
  - id: gather_airflow_context
    type: io.kestra.plugin.scripts.python.Script
    docker:
      image: python:3.11-slim
    script: |
      import json
      from datetime import datetime
      
      # Simulate Airflow API call
      context = {
          "system": "airflow",
          "dags_affected": ["daily_elt", "hourly_refresh"],
          "dag_failures_last_24h": 0,
          "last_successful_run": datetime.now().isoformat(),
          "expected_next_run": datetime.now().isoformat(),
          "is_currently_running": False,
          "recent_errors": []
      }
      
      print(f"✓ Gathered Airflow context")
      
      # Write output for AI Agent
      with open('airflow_context.json', 'w') as f:
          json.dump(context, f)
    outputFiles:
      - airflow_context.json

  # Step 3: Gather business context
  - id: gather_business_context
    type: io.kestra.plugin.scripts.python.Script
    docker:
      image: python:3.11-slim
    script: |
      import json
      from datetime import datetime
      
      # Simulate business/SLA context
      context = {
          "system": "business",
          "sla_refresh_time": "2 hours",
          "customers_affected": 45,
          "revenue_impact_per_hour": 2800,
          "critical_reports_using_data": ["executive_dashboard", "nps_metrics"],
          "business_hours": True,
          "on_call_engineer": "data-team"
      }
      
      print(f"✓ Gathered business context")
      
      # Write output for AI Agent
      with open('business_context.json', 'w') as f:
          json.dump(context, f)
    outputFiles:
      - business_context.json

  # Step 4: AI Agent analyzes all context and makes decision
  # Using Kestra's official AIAgent plugin with Gemini provider
  - id: analyze_with_ai_agent
    type: io.kestra.plugin.ai.agent.AIAgent
    
    # System prompt defines the agent's role and behavior
    systemMessage: |
      You are an expert data incident responder with deep knowledge of data platforms.
      
      Your job is to:
      1. Analyze data platform incidents across multiple systems
      2. Determine if this is a REAL incident or FALSE POSITIVE
      3. Assess SEVERITY (CRITICAL/HIGH/MEDIUM/LOW)
      4. Identify ROOT CAUSE
      5. Assess BUSINESS IMPACT
      6. Recommend ACTION (dismiss/log_only/notify_team/auto_fix)
      
      Always respond with ONLY valid JSON in this exact format:
      {
        "is_incident": true or false,
        "severity": "CRITICAL" or "HIGH" or "MEDIUM" or "LOW",
        "root_cause": "clear technical explanation",
        "business_impact": "description of business impact",
        "affected_count": number of affected systems/users,
        "recommended_action": "dismiss" or "log_only" or "notify_team" or "auto_fix",
        "confidence": 0.0 to 1.0,
        "reasoning": "brief explanation of your decision"
      }
    
    # User prompt with all the context
    prompt: |
      Analyze this incident:
      
      ALERT:
      {{ inputs.alert_data }}
      
      SNOWFLAKE CONTEXT:
      {{ read(outputs.gather_snowflake_context.outputFiles['snowflake_context.json']) }}
      
      AIRFLOW CONTEXT:
      {{ read(outputs.gather_airflow_context.outputFiles['airflow_context.json']) }}
      
      BUSINESS CONTEXT:
      {{ read(outputs.gather_business_context.outputFiles['business_context.json']) }}
      
      Based on all this information:
      1. Is this a REAL incident or FALSE POSITIVE?
      2. How CRITICAL is it (considering business impact)?
      3. What is the ROOT CAUSE?
      4. What ACTION should we take?
    
    # Configure Perplexity Sonar provider (OpenAI-compatible)
    # Perplexity Pro tier has unlimited Sonar usage
    provider:
      type: io.kestra.plugin.ai.provider.OpenAI
      apiKey: "{{ secret('PERPLEXITY_API_KEY') }}"
      baseUrl: "https://api.perplexity.ai"
      modelName: "sonar"

  # Step 5: Parse AI decision  
  - id: parse_decision
    type: io.kestra.plugin.scripts.python.Script
    docker:
      image: python:3.11-slim
    script: |
      import json
      import re
      
      # Per official Kestra example: AIAgent returns textOutput field
      ai_text = """{{ outputs.analyze_with_ai_agent.textOutput }}"""
      
      print("=" * 60)
      print("AI Agent Decision (from textOutput):")
      print(ai_text)
      print("=" * 60)
      
      # Strip markdown code blocks if present (```json ... ```)
      ai_text = ai_text.strip()
      if ai_text.startswith("```"):
          # Remove opening ```json or ```
          ai_text = re.sub(r'^```(?:json)?\s*\n', '', ai_text)
          # Remove closing ```
          ai_text = re.sub(r'\n```\s*$', '', ai_text)
          ai_text = ai_text.strip()
      
      try:
          decision = json.loads(ai_text)
      except json.JSONDecodeError as e:
          print(f"ERROR: Failed to parse AI response as JSON: {e}")
          print(f"Raw text (after markdown strip): {ai_text}")
          raise
      
      print("\n" + "=" * 60)
      print("✓ AI Decision Parsed Successfully:")
      print("=" * 60)
      print(f"  Is Incident: {decision.get('is_incident', 'N/A')}")
      print(f"  Severity: {decision.get('severity', 'N/A')}")
      print(f"  Root Cause: {decision.get('root_cause', 'N/A')[:100]}...")
      print(f"  Recommended Action: {decision.get('recommended_action', 'N/A')}")
      print(f"  Confidence: {decision.get('confidence', 0):.0%}")
      print(f"  Reasoning: {decision.get('reasoning', 'N/A')[:100]}...")
      print("=" * 60)
      
      # Write output for routing task
      with open('decision.json', 'w') as f:
          json.dump(decision, f)
      
      print("\n✓ Decision saved to decision.json")
    outputFiles:
      - decision.json

  # Step 6: Route based on AI decision
  - id: route_decision
    type: io.kestra.plugin.core.flow.Switch
    value: "{{ json(read(outputs.parse_decision.outputFiles['decision.json'])).recommended_action }}"
    cases:
      notify_team:
        - id: trigger_notification
          type: io.kestra.plugin.core.flow.Subflow
          namespace: incident_management
          flowId: notify_slack
          inputs:
            analysis: "{{ read(outputs.parse_decision.outputFiles['decision.json']) }}"
            incident_id: "{{ inputs.incident_id }}"
          wait: true
      
      auto_fix:
        - id: trigger_auto_fix
          type: io.kestra.plugin.core.flow.Subflow
          namespace: incident_management
          flowId: auto_remediate
          inputs:
            analysis: "{{ read(outputs.parse_decision.outputFiles['decision.json']) }}"
            incident_id: "{{ inputs.incident_id }}"
          wait: true
      
      log_only:
        - id: log_incident
          type: io.kestra.plugin.scripts.python.Script
          docker:
            image: python:3.11-slim
          script: |
            print("✓ Incident logged but not escalated (low priority)")
            print("  This will be tracked in incident database for patterns")
      
      dismiss:
        - id: dismiss_incident
          type: io.kestra.plugin.scripts.python.Script
          docker:
            image: python:3.11-slim
          script: |
            print("✓ Incident dismissed as FALSE POSITIVE")
            print("  AI Agent identified this as noise, filtering it out")
